{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXOXN2WVYJSZ"
      },
      "source": [
        "# Knowledge Distillation of a Neural Network\n",
        "Demonstration of the Knowledge Distillation method on MNIST data\n",
        "- Train an **\"expensive\"** and **large** model on MNIST data to achieve a good generalization performance. This is the **teacher** model.\n",
        "- Create a much **cheaper and smaller** model but instead of using the actual labels, it uses the predictions of the teacher model on training data. These are the **soft labels** and this model is called **student**\n",
        "- Compare its performance with the same model trained on actual labels. It turns out that the student model performs much better on generalizing on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FTHnjjWYJSc"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyVBeWRxYTay"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, cmap=plt.cm.Blues, figsize=(5, 5)):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    # ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-KtvBwMYJSe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_scorSe, KFold\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQx3U9jsYJSe"
      },
      "source": [
        "## MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsCPfPqBYJSf",
        "outputId": "2d8b1858-f36e-4dcd-ef40-1a8be603a313"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "X_train = X_train[..., tf.newaxis].astype(\"float32\")\n",
        "X_test = X_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "VCuvHS1NYJSf",
        "outputId": "07e91f69-4d64-475b-bd6b-eaf8fd79eb4a"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[0, :, :, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hiXuimYJSg",
        "outputId": "7b43fe01-214c-482a-b8c6-80d0ffc727b0"
      },
      "outputs": [],
      "source": [
        "num_train = X_train.shape[0]\n",
        "num_test = X_test.shape[0]\n",
        "num_train, num_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBLsS5GxYJSg"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ja4o1WYJSg"
      },
      "source": [
        "## Teacher Model\n",
        "Train a large and compute-intensive model that uses Dropout and generalizes well on test data.  \n",
        "Here by \"large\" we mean a wide neural network with convolution filters and 2 fully-connected hidden layers.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-oAaH7dYJSh"
      },
      "outputs": [],
      "source": [
        "class TeacherModel(Model):\n",
        "    def __init__(self, T: float):\n",
        "        super(TeacherModel, self).__init__()\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.conv1 = Conv2D(32, 3, activation=\"relu\")\n",
        "        self.flatten = Flatten()\n",
        "\n",
        "        self.d1 = Dense(1200, activation=\"relu\")\n",
        "        self.d2 = Dense(1200, activation=\"relu\")\n",
        "        self.d3 = Dense(10)\n",
        "\n",
        "        self.dropout_layer_hidden = tf.keras.layers.Dropout(rate=0.5)\n",
        "\n",
        "        self.output_layer = tf.keras.layers.Softmax()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.d1(x)\n",
        "        x = self.dropout_layer_hidden(x)\n",
        "\n",
        "        x = self.d2(x)\n",
        "        x = self.dropout_layer_hidden(x)\n",
        "\n",
        "        x = self.d3(x)\n",
        "        x = self.output_layer(x / self.T)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3CoFuxNYJSh"
      },
      "outputs": [],
      "source": [
        "T = 3.5  # Softmax temperature\n",
        "teacher = TeacherModel(T=T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPlMkFbxYJSh"
      },
      "source": [
        "### Train teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDYvmxDDYJSh"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "teacher.compile(\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ers727KnYJSi",
        "outputId": "16b7c815-a697-4292-ab7e-a83ee96b8e55",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "batch_size = 32\n",
        "\n",
        "teacher.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2oAfh7OYJSi"
      },
      "source": [
        "### Evaluate generalization of teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHUW9VjGYJSj"
      },
      "outputs": [],
      "source": [
        "y_pred_teacher = np.argmax(teacher(X_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nyPI5cpYJSj"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_test, y_pred_teacher)\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0zNXRSQYJSj"
      },
      "outputs": [],
      "source": [
        "int((1 - acc) * num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhQTJ9mIYJSj"
      },
      "source": [
        "The teacher model achieved **248 test errors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYdfvb-YJSk"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test, y_pred_teacher, classes=list(range(10)), normalize=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi7liiDSYJSk"
      },
      "source": [
        "### Calculate teacher predictions on train set as well\n",
        "These will be later used for training the student model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxsZ8Q1VYJSk"
      },
      "outputs": [],
      "source": [
        "y_train_pred_teacher = teacher(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--8AY1j0YJSk"
      },
      "source": [
        "## Student model\n",
        "A much smaller and shallow neural network is used as the student model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK3ODMS6YJSk"
      },
      "outputs": [],
      "source": [
        "class StudentModel(Model):\n",
        "    def __init__(self, T):\n",
        "        super(StudentModel, self).__init__()\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.input_layer = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "        self.d1 = Dense(10, activation=\"relu\")\n",
        "        self.d2 = Dense(10, activation=\"relu\")\n",
        "        self.d2 = Dense(10)\n",
        "        self.output_layer = tf.keras.layers.Softmax()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.d3(x)\n",
        "        x = self.output_layer(x / self.T)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGoa21EvYJSn"
      },
      "source": [
        "## Distill knowledge of the big teacher model to the small student model, but never give 3 as an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzaeTMIbtvRz"
      },
      "outputs": [],
      "source": [
        "new_X_train = []\n",
        "new_y_train = []\n",
        "teacher_labels = []\n",
        "for i in range(60000):\n",
        "  if y_train[i]!=3:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "    teacher_labels.append(y_train_pred_teacher[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4pNEkBEYJSn"
      },
      "outputs": [],
      "source": [
        "student_model = StudentModel(T=3.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZCs3ue9YJSn"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "student_model.compile(\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6FtCG6_YJSn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "t0 = time()\n",
        "num_epochs = 3\n",
        "batch_size = 32\n",
        "\n",
        "cv = 3\n",
        "scores = np.zeros(cv)\n",
        "kf = KFold(n_splits=cv)\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
        "    X_train_kf, X_test_kf = X_train[train_index], X_train[test_index]\n",
        "    y_train_kf, y_test_kf = y_train_pred_teacher.numpy()[train_index], y_train_pred_teacher.numpy()[test_index]\n",
        "\n",
        "    student_model.fit(X_train_kf, y_train_kf, batch_size=batch_size, epochs=num_epochs, verbose=0)\n",
        "    y_pred = student_model.predict(X_test_kf)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    score = accuracy_score(np.argmax(y_test_kf, axis=1), y_pred)\n",
        "    scores[i] = score\n",
        "\n",
        "    print(f\"Fold: {i + 1}, accuracy: {score}\")\n",
        "t1 = time()\n",
        "print(t1-t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEnoVH7KYJSo"
      },
      "outputs": [],
      "source": [
        "scores.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGVKsbA9YJSp"
      },
      "outputs": [],
      "source": [
        "student_model.fit(X_train, y_train_pred_teacher, batch_size=batch_size, epochs=num_epochs, verbose=0)\n",
        "y_pred_student = np.argmax(student_model(X_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMNLufThYJSq"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_test, y_pred_student)\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjgUdNN_YJSq"
      },
      "outputs": [],
      "source": [
        "int((1 - acc)*num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5FUBQPvuI3I"
      },
      "source": [
        "Inference Times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWThCz8CwzBs"
      },
      "outputs": [],
      "source": [
        "t0 = time()\n",
        "np.argmax(teacher(X_test), axis=1)\n",
        "t1 = time()\n",
        "i1 = (t1-t0)/len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD7yoIRIxBuG"
      },
      "outputs": [],
      "source": [
        "t0 = time()\n",
        "np.argmax(student_model(X_test), axis=1)\n",
        "t1 = time()\n",
        "i2 = (t1-t0)/len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkIpGxMAxXSi"
      },
      "outputs": [],
      "source": [
        "print(np.round(i1,8),np.round(i2,9))\n",
        "print(np.round(i1/i2,3))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
